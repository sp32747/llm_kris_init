{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13718598426177148"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas import SingleTurnSample\n",
    "from ragas.metrics import BleuScore\n",
    "\n",
    "test_data = {\n",
    "    \"user_input\": \"summarise given text\\nThe company reported an 8% rise in Q3 2024, driven by strong performance in the Asian market. Sales in this region have significantly contributed to the overall growth. Analysts attribute this success to strategic marketing and product localization. The positive trend in the Asian market is expected to continue into the next quarter.\",\n",
    "    \"response\": \"The company experienced an 8% increase in Q3 2024, largely due to effective marketing strategies and product adaptation, with expectations of continued growth in the coming quarter.\",\n",
    "    \"reference\": \"The company reported an 8% growth in Q3 2024, primarily driven by strong sales in the Asian market, attributed to strategic marketing and localized products, with continued growth anticipated in the next quarter.\"\n",
    "}\n",
    "metric = BleuScore()\n",
    "test_data = SingleTurnSample(**test_data)\n",
    "metric.single_turn_score(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os;\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.llms import OpenAI, Cohere\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGCHAIN_API_KEY=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "LANGCHAIN_PROJECT=\"CRAG using langgraph\"\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY=os.getenv(\"TAVILY_API_KEY\")  \n",
    "LANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "LANGCHAIN_TRACING_V2=True\n",
    "SERPAPI_API_KEY=os.getenv(\"SERPAPI_API_KEY\")\n",
    "RAGAS_APP_TOKEN=os.getenv(\"RAGAS_APP_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\"))\n",
    "evaluator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we will use AspectCritic, which an LLM based metric that outputs pass/fail given the evaluation criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas import SingleTurnSample\n",
    "from ragas.metrics import AspectCritic\n",
    "\n",
    "test_data = {\n",
    "    \"user_input\": \"summarise given text\\nThe company reported an 8% rise in Q3 2024, driven by strong performance in the Asian market. Sales in this region have significantly contributed to the overall growth. Analysts attribute this success to strategic marketing and product localization. The positive trend in the Asian market is expected to continue into the next quarter.\",\n",
    "    \"response\": \"The company experienced an 8% increase in Q3 2024, largely due to effective marketing strategies and product adaptation, with expectations of continued growth in the coming quarter.\",\n",
    "}\n",
    "\n",
    "metric = AspectCritic(name=\"summary_accuracy\",llm=evaluator_llm, definition=\"Verify if the summary is accurate.\")\n",
    "test_data = SingleTurnSample(**test_data)\n",
    "await metric.single_turn_ascore(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Component metrics evaluate the inputs and outputs of each component, for example precision @ K, nDCG, latency, toxicity, and so on. Compound metrics evaluate how multiple components interact: Faithfulness measures the generatorâ€™s adherence to the knowledge from a retriever that requires the chain input, chain output, and output of the internal retriever. Overall metrics evaluate the overall input and output of the system, for example, answer correctness and latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class RAG:\n",
    "    def __init__(self, model=\"gpt-4o\"):\n",
    "        self.llm = ChatOpenAI(model=model)\n",
    "        self.embeddings = OpenAIEmbeddings()\n",
    "        self.doc_embeddings = None\n",
    "        self.docs = None\n",
    "\n",
    "    def load_documents(self, documents):\n",
    "        \"\"\"Load documents and compute their embeddings.\"\"\"\n",
    "        self.docs = documents\n",
    "        self.doc_embeddings = self.embeddings.embed_documents(documents)\n",
    "\n",
    "    def get_most_relevant_docs(self, query):\n",
    "        \"\"\"Find the most relevant document for a given query.\"\"\"\n",
    "        if not self.docs or not self.doc_embeddings:\n",
    "            raise ValueError(\"Documents and their embeddings are not loaded.\")\n",
    "\n",
    "        query_embedding = self.embeddings.embed_query(query)\n",
    "        similarities = [\n",
    "            np.dot(query_embedding, doc_emb)\n",
    "            / (np.linalg.norm(query_embedding) * np.linalg.norm(doc_emb))\n",
    "            for doc_emb in self.doc_embeddings\n",
    "        ]\n",
    "        most_relevant_doc_index = np.argmax(similarities)\n",
    "        return [self.docs[most_relevant_doc_index]]\n",
    "\n",
    "    def generate_answer(self, query, relevant_doc):\n",
    "        \"\"\"Generate an answer for a given query based on the most relevant document.\"\"\"\n",
    "        prompt = f\"question: {query}\\n\\nDocuments: {relevant_doc}\"\n",
    "        messages = [\n",
    "            (\"system\", \"You are a helpful assistant that answers questions based on given documents only.\"),\n",
    "            (\"human\", prompt),\n",
    "        ]\n",
    "        ai_msg = self.llm.invoke(messages)\n",
    "        return ai_msg.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_docs = [\n",
    "    \"Albert Einstein proposed the theory of relativity, which transformed our understanding of time, space, and gravity.\",\n",
    "    \"Marie Curie was a physicist and chemist who conducted pioneering research on radioactivity and won two Nobel Prizes.\",\n",
    "    \"Isaac Newton formulated the laws of motion and universal gravitation, laying the foundation for classical mechanics.\",\n",
    "    \"Charles Darwin introduced the theory of evolution by natural selection in his book 'On the Origin of Species'.\",\n",
    "    \"Ada Lovelace is regarded as the first computer programmer for her work on Charles Babbage's early mechanical computer, the Analytical Engine.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Who introduced the theory of relativity?\n",
      "Relevant Document: ['Albert Einstein proposed the theory of relativity, which transformed our understanding of time, space, and gravity.']\n",
      "Answer: Albert Einstein introduced the theory of relativity.\n"
     ]
    }
   ],
   "source": [
    "# Initialize RAG instance\n",
    "rag = RAG()\n",
    "\n",
    "# Load documents\n",
    "rag.load_documents(sample_docs)\n",
    "\n",
    "# Query and retrieve the most relevant document\n",
    "query = \"Who introduced the theory of relativity?\"\n",
    "relevant_doc = rag.get_most_relevant_docs(query)\n",
    "\n",
    "# Generate an answer\n",
    "answer = rag.generate_answer(query, relevant_doc)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Relevant Document: {relevant_doc}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect Evaluation Data\n",
    "To collect evaluation data, we first need a set of queries to run against our RAG. We can run the queries through the RAG system and collect the response, retrieved_contextsfor each query. You may also optionally prepare a set of golden answers for each query to evaluate the system's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_queries = [\n",
    "    \"Who introduced the theory of relativity?\",\n",
    "    \"Who was the first computer programmer?\",\n",
    "    \"What did Isaac Newton contribute to science?\",\n",
    "    \"Who won two Nobel Prizes for research on radioactivity?\",\n",
    "    \"What is the theory of evolution by natural selection?\"\n",
    "]\n",
    "\n",
    "expected_responses = [\n",
    "    \"Albert Einstein proposed the theory of relativity, which transformed our understanding of time, space, and gravity.\",\n",
    "    \"Ada Lovelace is regarded as the first computer programmer for her work on Charles Babbage's early mechanical computer, the Analytical Engine.\",\n",
    "    \"Isaac Newton formulated the laws of motion and universal gravitation, laying the foundation for classical mechanics.\",\n",
    "    \"Marie Curie was a physicist and chemist who conducted pioneering research on radioactivity and won two Nobel Prizes.\",\n",
    "    \"Charles Darwin introduced the theory of evolution by natural selection in his book 'On the Origin of Species'.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "for query,reference in zip(sample_queries,expected_responses):\n",
    "\n",
    "    relevant_docs = rag.get_most_relevant_docs(query)\n",
    "    response = rag.generate_answer(query, relevant_docs)\n",
    "    dataset.append(\n",
    "        {\n",
    "            \"user_input\":query,\n",
    "            \"retrieved_contexts\":relevant_docs,\n",
    "            \"response\":response,\n",
    "            \"reference\":reference\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import EvaluationDataset\n",
    "evaluation_dataset = EvaluationDataset.from_list(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate\n",
    "We have successfully collected the evaluation data. Now, we can evaluate our RAG system on the collected dataset using a set of commonly used RAG evaluation metrics. You may choose any model as evaluator LLM for evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c60d27c3434547ad928aac520a7c7578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'context_recall': 1.0000, 'faithfulness': 0.7667, 'factual_correctness': 0.7400}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(llm)\n",
    "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness\n",
    "\n",
    "result = evaluate(dataset=evaluation_dataset,metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness()],llm=evaluator_llm)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Results  \n",
    "app.ragas.io "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results uploaded! View at https://app.ragas.io/dashboard/alignment/evaluation/4499492c-cfb4-4e72-9d2b-f297cc6299ba\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://app.ragas.io/dashboard/alignment/evaluation/4499492c-cfb4-4e72-9d2b-f297cc6299ba'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
