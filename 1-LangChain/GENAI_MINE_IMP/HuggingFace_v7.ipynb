{"cells":[{"cell_type":"markdown","metadata":{"id":"lDs9DRHeU0lA"},"source":["##Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4UkbG0gAAOzf"},"outputs":[],"source":["!pip -q install accelerate -U\n","!pip -q install transformers[torch]\n","!pip -q install datasets\n","#Restart after installing"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"fo9M10uMU5Ea"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import plotly.express as px\n","from transformers import pipeline"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"vDK0x4ifHzdo"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"dUKTA2TCK0Bm"},"source":["# Hugging Face models - Pipeline()"]},{"cell_type":"markdown","metadata":{"id":"owPpa22P79T4"},"source":["## Sentiment Analysis Model"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"Iqbx0s86EKjR"},"outputs":[],"source":["from transformers import pipeline"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import os\n","from dotenv import load_dotenv\n","load_dotenv()\n","\n","os.environ['HF_TOKEN']=os.getenv(\"HF_TOKEN\")"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"hasDCZe3EKr5"},"outputs":[{"name":"stderr","output_type":"stream","text":["No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n","Using a pipeline without specifying a model name and revision in production is not recommended.\n"]},{"ename":"RuntimeError","evalue":"Failed to import transformers.models.distilbert.modeling_tf_distilbert because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","File \u001b[1;32mc:\\Users\\WIN-10\\anaconda3\\Lib\\site-packages\\transformers\\activations_tf.py:22\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tf_keras'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","File \u001b[1;32mc:\\Users\\WIN-10\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1603\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1602\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1604\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[1;32mc:\\Users\\WIN-10\\anaconda3\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n","File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n","File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n","File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n","File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n","File \u001b[1;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n","File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n","File \u001b[1;32mc:\\Users\\WIN-10\\anaconda3\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations_tf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tf_activation\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_tf_outputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     29\u001b[0m     TFBaseModelOutput,\n\u001b[0;32m     30\u001b[0m     TFMaskedLMOutput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     TFTokenClassifierOutput,\n\u001b[0;32m     35\u001b[0m )\n","File \u001b[1;32mc:\\Users\\WIN-10\\anaconda3\\Lib\\site-packages\\transformers\\activations_tf.py:27\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parse(keras\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mmajor \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     28\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour currently installed version of Keras is Keras 3, but this is not yet supported in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformers. Please install the backwards-compatible tf-keras package with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install tf-keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     31\u001b[0m         )\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gelu\u001b[39m(x):\n","\u001b[1;31mValueError\u001b[0m: Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.","\nThe above exception was the direct cause of the following exception:\n","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sentiment_task \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment-analysis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m sentiment_task(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCovid cases are increasing fast!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[1;32mc:\\Users\\WIN-10\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:895\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    894\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[1;32m--> 895\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m infer_framework_load_model(\n\u001b[0;32m    896\u001b[0m         model,\n\u001b[0;32m    897\u001b[0m         model_classes\u001b[38;5;241m=\u001b[39mmodel_classes,\n\u001b[0;32m    898\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m    899\u001b[0m         framework\u001b[38;5;241m=\u001b[39mframework,\n\u001b[0;32m    900\u001b[0m         task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[0;32m    901\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs,\n\u001b[0;32m    902\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m    903\u001b[0m     )\n\u001b[0;32m    905\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m    906\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n","File \u001b[1;32mc:\\Users\\WIN-10\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\base.py:261\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    259\u001b[0m         classes\u001b[38;5;241m.\u001b[39mappend(_class)\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m look_tf:\n\u001b[1;32m--> 261\u001b[0m     _class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(transformers_module, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTF\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marchitecture\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    263\u001b[0m         classes\u001b[38;5;241m.\u001b[39mappend(_class)\n","File \u001b[1;32mc:\\Users\\WIN-10\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1594\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1592\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1593\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m-> 1594\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1596\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[1;32mc:\\Users\\WIN-10\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1593\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1591\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[0;32m   1592\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1593\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[0;32m   1594\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[1;32mc:\\Users\\WIN-10\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1605\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1604\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1605\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1606\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1607\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1608\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n","\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.models.distilbert.modeling_tf_distilbert because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`."]}],"source":["sentiment_task = pipeline(\"sentiment-analysis\")\n","sentiment_task(\"Covid cases are increasing fast!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_o9ehxYhEKuy"},"outputs":[],"source":["senti_model(\"This movie is damn good. I loved it\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HLm9YvnHEKx7"},"outputs":[],"source":["senti_model(\"This is a bad phone. The screen and battery are of poor quality.\")"]},{"cell_type":"markdown","metadata":{"id":"HUr-TS8_8AMH"},"source":["## Sentiment Analysis Model-2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hno4ArGtACMZ"},"outputs":[],"source":["Senti_model_2 = pipeline(task=\"sentiment-analysis\",\n","                         model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A_f-HrS2AUqW"},"outputs":[],"source":["Senti_model_2(\"Over heating issue don't by this product camera was good\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WTVT8t5AAusv"},"outputs":[],"source":["Senti_model_2(\"Waste of money\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1ajo60hlA34F"},"outputs":[],"source":["Senti_model_2(\"Nice product under 24k .... overall good\")"]},{"cell_type":"markdown","metadata":{"id":"OnHzKrVbOcB0"},"source":["## Prediction on your dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b3xBKkh9Ohoy"},"outputs":[],"source":["import pandas as pd\n","user_review_data=pd.read_csv(\"https://raw.githubusercontent.com/venkatareddykonasani/Datasets/master/Amazon_Yelp_Reviews/Review_Data.csv\")\n","user_review_data=user_review_data.sample(50)\n","user_review_data[\"Review\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"orvgbqqMOhr6"},"outputs":[],"source":["user_review_data[\"Predicted_Sentiment\"] = user_review_data[\"Review\"].apply(lambda x: Senti_model_2(x)[0][\"label\"])\n","user_review_data"]},{"cell_type":"markdown","metadata":{"id":"yBFCPGdZpCHm"},"source":["## Load the model on GPU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uKL7cOZbUvHR"},"outputs":[],"source":["Senti_model_2_gpu = pipeline(task=\"sentiment-analysis\",\n","                         model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n","                         device=\"cuda\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FLG1kfWYWJYR"},"outputs":[],"source":["user_review_data[\"Predicted_Sentiment\"] = user_review_data[\"Review\"].apply(lambda x: Senti_model_2_gpu(x)[0][\"label\"])\n","user_review_data"]},{"cell_type":"markdown","metadata":{"id":"5XuiFIE2lP3F"},"source":["## Language Translation Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tOD9eWGClMHd"},"outputs":[],"source":["translator_model = pipeline(task=\"translation_en_to_fr\",\n","                            model=\"google-t5/t5-small\",\n","                            device=\"cuda\")\n","translator_model(\"Good bye\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3XFeJM7wpfGj"},"outputs":[],"source":["#Clear the cache in GPU\n","import torch\n","torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"FrFOXzUCtj9D"},"source":["## Question and Answer Based on a Document"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NrQG06JItsjz"},"outputs":[],"source":["qa_model = pipeline(task=\"question-answering\",\n","                    model=\"deepset/roberta-base-squad2\",\n","                    device=\"cuda\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dsAHxf1xyNZA"},"outputs":[],"source":["# If you get any locale related error\n","'''\n","import locale\n","print(locale.getpreferredencoding())\n","\n","def getpreferredencoding(do_setlocale = True):\n","    return \"UTF-8\"\n","locale.getpreferredencoding = getpreferredencoding\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PJYJJ2upt2r6"},"outputs":[],"source":["#Importing computer_scientists.txt document from github\n","!wget https://raw.githubusercontent.com/venkatareddykonasani/Datasets/master/computer_scientists/computer_scientists.txt\n","document=open(\"computer_scientists.txt\").read()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y3H2_V_6t60E"},"outputs":[],"source":["qa_model({'question':\"Who is the first computer programmer?\",\n","          'context':document})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kWnKev1hvk6h"},"outputs":[],"source":["qa_model({'question':\"What did Yann LeCun contribute?\",\n","          'context':document})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vTT84KvAz81F"},"outputs":[],"source":["qa_model({'question':\"Who is the father of deep learning?\",\n","          'context':document})"]},{"cell_type":"markdown","metadata":{"id":"k91FClC4rUhC"},"source":["## NER (Name Entity Recognition) Model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UAJDsLvs3ctv"},"outputs":[],"source":["ner_model = pipeline(task=\"ner\",\n","                     model=\"dslim/bert-base-NER\",\n","                     device=\"cuda\",\n","                     aggregation_strategy=\"simple\")\n","#aggregation_strategy =\"Simple\" ; simplifies the output and makes it easy to read\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VcYMkTmQ3gu2"},"outputs":[],"source":["sample_doc=\"\"\"\n","Hello,\n","  I, John Smith, a member of the Tech Innovators team, would like to schedule a meeting with you,\n","  Mary Johnson, from the Quantum Solutions group, on Tuesday, February 8th, 2024, at 10:00 AM.\n","  We can meet at your office in San Francisco or, if more convenient, at the Cafe Bella in New York City.\n","  Please let me know if this date and time work for you.\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bvn5Vlwv5L7P"},"outputs":[],"source":["entities = ner_model(sample_doc)\n","print(entities)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pgQMV9UQ5rlS"},"outputs":[],"source":["# Convert the above output into a dataframe and print it with the entity name\n","NER_result = pd.DataFrame(entities, columns=[\"word\", \"entity_group\"])\n","\n","# Print the DataFrame\n","print(NER_result)\n"]},{"cell_type":"markdown","metadata":{"id":"_lrcBe5ejRV9"},"source":["## Text Summarization Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sA5GowuK6TCR"},"outputs":[],"source":["summarizer_model = pipeline(task=\"summarization\",\n","                            model=\"google/pegasus-xsum\",\n","                            device=\"cuda\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Z-8rQXe6bfF"},"outputs":[],"source":["Book_essay = \"\"\"\n","The 7 Habits of Highly Effective People\" is a timeless self-help book by Stephen R. Covey that offers a holistic approach to personal and professional effectiveness. The book is a guide to transforming one's life by adopting seven fundamental habits.\n","Covey's philosophy centers on the idea that true success is achieved by aligning one's values with principles that govern human effectiveness. The first three habits focus on personal development, emphasizing the importance of taking control of one's life, setting clear goals, and prioritizing tasks based on importance rather than urgency.\n","The next three habits delve into the concept of interdependence, emphasizing the significance of effective communication, cooperation, and collaboration in achieving mutually beneficial outcomes. Covey argues that fostering strong interpersonal relationships and empathetic listening are key to building trust and synergy.\n","The seventh habit, \"Sharpen the Saw,\" encourages continuous self-renewal and personal growth through physical, mental, emotional, and spiritual well-being.\n","Throughout the book, Covey provides practical advice and real-life examples to illustrate each habit's application in various aspects of life, from family and work to leadership and community involvement. \"The 7 Habits of Highly Effective People\" has had a profound impact on individuals seeking personal and professional growth, offering a framework for achieving lasting success and a sense of fulfillment..\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c_EDurlV7u9Q"},"outputs":[],"source":["print(summarizer_model(Book_essay, max_length=120, min_length=30))"]},{"cell_type":"markdown","metadata":{"id":"yq-viv3QDAT_"},"source":["## Text Generation Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-9jLaxAj7_Nz"},"outputs":[],"source":["text_generator_model = pipeline(task=\"text-generation\",\n","                                model=\"gpt2\",\n","                                device=\"cuda\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vYPSOfJlDLvo"},"outputs":[],"source":["# Generate text starting with the given prompt\n","text_result = text_generator_model(\"The best way to start a presentation is\")\n","print(text_result)"]},{"cell_type":"markdown","metadata":{"id":"tlqySLbBv1rD"},"source":["# Hugging Face models without pipeline()"]},{"cell_type":"markdown","metadata":{"id":"pMErYtwhK-CV"},"source":["## Sentiment Analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AAtrFzinDMqI"},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n","\n","model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5I3a2q9L23ui"},"outputs":[],"source":["import numpy as np\n","raw_text = \"This is a great book\"\n","encoded_input = tokenizer(raw_text, return_tensors='pt')\n","output = model(**encoded_input)\n","logits = output.logits.detach().numpy()\n","y_pred = np.argmax(logits)\n","y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jISpOd5j1WNY"},"outputs":[],"source":["#Code for passing multiple examples to the above model\n","\n","import numpy as np\n","# Prepare the input texts\n","texts = [\n","    \"This is a great book\",\n","    \"The food was not tasty and it was very cold\",\n","    \"The weather is very good today\",\n","]\n","\n","# Tokenize and encode the input texts\n","encoded_inputs = tokenizer(texts, padding=True, return_tensors=\"pt\")\n","\n","# Pass the encoded inputs to the model\n","outputs = model(**encoded_inputs)\n","\n","# Get the model's predictions\n","logits = outputs.logits.detach().cpu().numpy()\n","\n","# Find the predicted class for each input\n","predictions = np.argmax(logits, axis=1)\n","\n","# Print the predictions\n","print(predictions)\n"]},{"cell_type":"markdown","metadata":{"id":"_EbNv3bmBF7V"},"source":["# Finetuning HuggingFace model\n","Code Explanation- [Click here](https://github.com/venkatareddykonasani/Assorted/blob/main/Fine_tuning_HuggingFace.md)"]},{"cell_type":"markdown","metadata":{"id":"nYFE5O8RB4MD"},"source":["### Bank Complaints Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BGkqrKxCfrHy"},"outputs":[],"source":["!wget https://github.com/venkatareddykonasani/Datasets/raw/master/Bank_Customer_Complaints/complaints_v2.zip\n","!unzip -o complaints_v2.zip\n","complaints_data = pd.read_csv(\"/content/complaints_v2.csv\")\n","complaints_data.head()"]},{"cell_type":"markdown","metadata":{"id":"hqmjOcoOB-ec"},"source":["### Use distilbert model without finetunung"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8BJkxMer_wjr"},"outputs":[],"source":["# Distil bert model\n","from transformers import pipeline\n","distilbert_model = pipeline(task=\"text-classification\",\n","                            model=\"distilbert-base-uncased\",\n","                            )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2WbHzWMRDiRW"},"outputs":[],"source":["sample_data=complaints_data.sample(100, random_state=42)\n","sample_data[\"text\"]=sample_data[\"text\"].apply(lambda x: \" \".join(x.split()[:350]))\n","sample_data[\"bert_predicted\"] = sample_data[\"text\"].apply(lambda x: distilbert_model(x)[0][\"label\"])\n","#Default prediction is not a number LABEL_1, LABEL_0\n","sample_data[\"bert_predicted_num\"]=sample_data[\"bert_predicted\"].apply(lambda x: x[-1])\n","sample_data[\"bert_predicted_num\"] = sample_data[\"bert_predicted_num\"].astype(int)\n","sample_data.head()"]},{"cell_type":"markdown","metadata":{"id":"CRx_9gXrklH4"},"source":["### Accuracy of the model without fine-tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W_LxeuwUIg6r"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","cm = confusion_matrix(sample_data[\"label\"], sample_data[\"bert_predicted_num\"])\n","print(cm)\n","accuracy=cm.diagonal().sum()/cm.sum()\n","print(accuracy)"]},{"cell_type":"markdown","metadata":{"id":"8IoArWg3ksvC"},"source":["## Project - Finetuning the model with our data\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wvhIoOLQBG8I"},"outputs":[],"source":["!pip -q install accelerate -U\n","!pip -q install transformers[torch]\n","!pip -q install datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jZT4RxigoO3a"},"outputs":[],"source":["from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n","from transformers import Trainer, TrainingArguments\n","from datasets import load_dataset, DatasetDict, ClassLabel, Dataset\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BF1wh7rY4MtP"},"outputs":[],"source":["#The target variable must be named as \"label\" - Verify it, before proceeding\n","print(sample_data.columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cXivZhOxjQtA"},"outputs":[],"source":["Sample_data = Dataset.from_pandas(sample_data)\n","# Split the dataset into training and testing sets\n","train_test_split = Sample_data.train_test_split(test_size=0.2)  # 80% training, 20% testing\n","dataset = DatasetDict({\n","    'train': train_test_split['train'],\n","    'test': train_test_split['test']\n","})\n","dataset"]},{"cell_type":"markdown","metadata":{"id":"mYxjyEgRR2p-"},"source":["### Load the tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"khB_bZv0lcXL"},"outputs":[],"source":["# Load the tokenizer\n","tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","\n","# Padding\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.pad_token_id = tokenizer.eos_token_id\n","tokenizer.add_special_tokens({'pad_token': '[PAD]'} )\n","\n","def tokenize_function(examples):\n","    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n","tokenized_datasets = dataset.map(tokenize_function, batched=True)"]},{"cell_type":"markdown","metadata":{"id":"l_Q_vJOISAtX"},"source":["### Load and Train the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LcBw9CWmf0_D"},"outputs":[],"source":["model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased',\n","                                                            num_labels=2,\n","                                                            pad_token_id=tokenizer.eos_token_id) # Adjust num_labels as needed\n","model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bbMzSADKvCtB"},"outputs":[],"source":["training_args = TrainingArguments(\n","    output_dir=\"./results_bert_custom\",\n","    num_train_epochs=1,\n","    logging_dir=\"./logs_bert_custom\",\n","    evaluation_strategy=\"epoch\",\n",")\n","\n","# Initialize the Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_datasets['train'],\n","    eval_dataset=tokenized_datasets['test'],\n",")\n","\n","# Start training\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FIVONC0H7YZc"},"outputs":[],"source":["# Define the directory where you want to save your model and tokenizer\n","model_dir = \"./distilbert_finetuned\"\n","\n","# Save the model\n","model.save_pretrained(model_dir)\n","\n","# Save the tokenizer\n","tokenizer.save_pretrained(model_dir)\n","\n","#Save the model with\n","trainer.save_model('Distilbert_CustomModel_10K')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x5zPdvspOrjc"},"outputs":[],"source":["def make_prediction(text):\n","  new_complaint=text\n","  inputs=tokenizer(new_complaint, return_tensors=\"pt\")\n","  inputs = inputs.to(torch.device(\"cuda:0\"))\n","  outputs=model(**inputs)\n","  predictions=outputs.logits.argmax(-1)\n","  predictions=predictions.detach().cpu().numpy()\n","  return(predictions)\n","\n","sample_data[\"finetuned_predicted\"]=sample_data[\"text\"].apply(lambda x: make_prediction(str(x))[0])\n","sample_data.sample(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o8BsIrTyWc72"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","# Create the confusion matrix\n","cm1 = confusion_matrix(sample_data[\"label\"], sample_data[\"finetuned_predicted\"])\n","print(cm1)\n","accuracy1=cm1.diagonal().sum()/cm1.sum()\n","print(accuracy1)"]},{"cell_type":"markdown","metadata":{"id":"vIwrPpOpzawh"},"source":["### Loading a pre-built model and making prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kmhTs6AAzFDI"},"outputs":[],"source":["#Code to donwloading the distilbert model\n","!gdown --id 1785J3ir19RaZP3ebbFvWUX88PMaBouro -O distilbert_finetuned_V1.zip\n","!unzip -o -j distilbert_finetuned_V1.zip -d distilbert_finetuned_V1\n","\n","model_v1 = DistilBertForSequenceClassification.from_pretrained('/content/distilbert_finetuned_V1')\n","model_v1.to(\"cuda:0\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HCJz8FD99xcK"},"outputs":[],"source":["def make_prediction(text):\n","  new_complaint=text\n","  inputs=tokenizer(new_complaint, return_tensors=\"pt\")\n","  inputs = inputs.to(torch.device(\"cuda:0\"))\n","  outputs=model_v1(**inputs)\n","  predictions=outputs.logits.argmax(-1)\n","  predictions=predictions.detach().cpu().numpy()\n","  return(predictions)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"99Z7s9P-C-hg"},"outputs":[],"source":["sample_data_large=complaints_data.sample(n=1000, random_state=55)\n","sample_data_large[\"finetuned_predicted\"]=sample_data_large[\"text\"].apply(lambda x: make_prediction(str(x)[:350])[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qLAOpceYfkWI"},"outputs":[],"source":["sample_data_large[\"finetuned_predicted\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b9Iq2KJD-AJ5"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","# Create the confusion matrix\n","cm1 = confusion_matrix(sample_data_large[\"label\"], sample_data_large[\"finetuned_predicted\"])\n","print(cm1)\n","accuracy1=cm1.diagonal().sum()/cm1.sum()\n","print(accuracy1)"]},{"cell_type":"markdown","metadata":{"id":"vm1l0v6Dx-jb"},"source":["# Saving the Model on HuggingFace hub"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S6SPRqIiynQW"},"outputs":[],"source":["!pip install transformers\n","!pip install huggingface_hub\n","!pip install -U ipykernel #for executing the commands\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rcqXDgoizIyD"},"outputs":[],"source":["from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9gmtZkvqDJNV"},"outputs":[],"source":["!gdown --id 1785J3ir19RaZP3ebbFvWUX88PMaBouro -O distilbert_finetuned_V1.zip\n","!unzip -o -j distilbert_finetuned_V1.zip -d distilbert_finetuned_V1\n","\n","model = DistilBertForSequenceClassification.from_pretrained('/content/distilbert_finetuned_V1')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iJmy5o-I0SGn"},"outputs":[],"source":["import os\n","os.environ['HUGGINGFACEHUB_API_TOKEN']=\"YOUR ACCESS TOKEN\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hs-qSjk-z0dd"},"outputs":[],"source":["from huggingface_hub import notebook_login\n","notebook_login()\n","#To get Auth token: Profile >> Settings >>Access Token"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NRPRvUh-0esS"},"outputs":[],"source":["model.push_to_hub(\"venkatareddykonasani/Bank_distil_bert_10K\")"]},{"cell_type":"markdown","metadata":{"id":"JFnoFMsHBEw8"},"source":["# Loading the model from HuggingFace hub"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7FbKUERK0k5p"},"outputs":[],"source":["model=DistilBertForSequenceClassification.from_pretrained(\"venkatareddykonasani/Bank_distil_bert_10K\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GsKSd1EM1DS1"},"outputs":[],"source":["from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n","\n","tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qGd2quFz1Hss"},"outputs":[],"source":["import pandas as pd\n","!wget https://github.com/venkatareddykonasani/Datasets/raw/master/Bank_Customer_Complaints/complaints_v2.zip\n","!unzip -o complaints_v2.zip\n","complaints_data = pd.read_csv(\"/content/complaints_v2.csv\")\n","list(complaints_data[\"text\"].head())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PyRrPXtF2YFe"},"outputs":[],"source":["import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k_2szgSb1rcc"},"outputs":[],"source":["complaint=\"\"\"\n","payment history missing credit report made mistake put account forbearance without authorization knowledge matter fact automatic payment setup month monthly mortgage paid full noticed issue account marked forbearance credit report tried get new home loan another new bank contacted immediately asked fix error provide letter detail please see asks forbearance issue seemed fixed however credit report payment history missing new bank able approve new loan issue missing payment history contacted time since phone ask thing report payment history transunion fix missing data issue provide letter show account never forbearance payment history past month however waiting week countless email phone call talk multiple supervisor able get either one thing without issue fixed new bank process new loan application therefore need help immediately get fixed\n","\"\"\"\n","\n","inputs=tokenizer(complaint, return_tensors=\"pt\")\n","outputs=model(**inputs)\n","predictions=outputs.logits.argmax(-1)\n","predictions=predictions.detach().cpu().numpy()\n","print(predictions)"]},{"cell_type":"markdown","metadata":{"id":"fTFBcRMfBM6W"},"source":["# Web App Creation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oIkhfFOwkLY7"},"outputs":[],"source":["%%writefile requirements.txt\n","streamlit\n","numpy\n","pandas\n","torch\n","transformers\n","huggingface_hub"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Opz4IsR8mOH8"},"outputs":[],"source":["!pip install -r requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ZYun4Kf2UkY"},"outputs":[],"source":["%%writefile app.py\n","import streamlit as st\n","import numpy as np\n","import pandas as pd\n","import torch\n","from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n","\n","tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","model = DistilBertForSequenceClassification.from_pretrained('venkatareddykonasani/Bank_distil_bert_10K')\n","\n","st.title(\"Bank Complaints Categorization\")\n","st.write(\"Sample Complaints are given below\")\n","Sample_Complaints = [\n","    {\"Sentence\": \"Credit Report - payment history missing credit report made mistake put account forbearance without authorization \"},\n","    {\"Sentence\": \"Retail Related - forwarded message cc sent friday pdt subject final legal payment well fargo well fargo clearly wrong need look actually opened account see court hearing several different government agency \"}\n","]\n","st.table(Sample_Complaints)\n","user_input = st.text_input(\"Enter a complaint:\")\n","button=st.button(\"Classify\")\n","\n","d={\n","    0: \"Credit reporting\",\n","    1: \"Mortgage and Others\"\n","}\n","\n","if user_input and button:\n","  inputs=tokenizer(user_input, return_tensors=\"pt\")\n","  outputs=model(**inputs)\n","  predictions=outputs.logits.argmax(-1)\n","  predictions=predictions.detach().cpu().numpy()\n","  print(predictions)\n","  st.write(\"Prediction :\" , d[predictions[0]])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YIaHczsX-wT0"},"outputs":[],"source":["!streamlit run app.py & npx localtunnel --port 8501 & curl ipv4.icanhazip.com\n","\n","#This sometimes doesn't work on Chrome"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m4zPgyAw_-ko"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPrXTTVq6d23irLtTksFhhh","gpuType":"T4","machine_shape":"hm","mount_file_id":"1g583Kvn4EAGwKflKQIwkfJty-jK9FeSc","provenance":[]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
